{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "from dateutil import parser\n",
    "import fiona\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import pygsheets\n",
    "import rtree\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "import shapely.geometry\n",
    "\n",
    "creds = pygsheets.authorize(service_file='/home/thejakeschmidt/311-open-data-analysis/client_secret.json')\n",
    "\n",
    "SUMMONS_DESCRIPTION = 'The Police Department issued a summons in response to the complaint.'\n",
    "ACTION_DESCRIPTION = 'The Police Department responded to the complaint and took action to fix the condition.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data and add calculated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_data():\n",
    "    # illegal_parking.csv is the data from\n",
    "    # https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/7ahn-ypff, manually filtered to the rows containing the string \"Illegal Parking\".\n",
    "    data = pd.read_csv('data/illegal_parking.csv')\n",
    "    series = data.groupby('Resolution Description').size().sort_values(ascending=False)\n",
    "    series.name = 'count'\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date_and_time_columns(data):\n",
    "    data['Created Date'] = pd.to_datetime(data['Created Date'])\n",
    "    data['Calculated Year'] = data['Created Date'].map(lambda date: date.year)\n",
    "    data['Calculated Closed Date'] = data['Closed Date'].apply(\n",
    "        lambda datestr:\n",
    "        np.datetime64('NaT') if (pd.isnull(datestr) or datestr == '01/01/1900 12:00:00 AM')\n",
    "        else parser.parse(datestr))\n",
    "    data['Calculated Resolution Time'] = data['Calculated Closed Date'] - data['Created Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_community_board_column(data):\n",
    "    \"\"\"The raw \"Community Board\" column is formatted like \"01 MANHATTAN\". This adds one formatted like \"Manhattan CB1\".\"\"\"\n",
    "    def reformat_community_board(cb):\n",
    "        parts = cb.split(' ', 1)\n",
    "        return parts[1].title() + \" CB\" + (str(int(parts[0])) if parts[0] != 'Unspecified' else parts[0])\n",
    "    data['Calculated Community Board'] = data['Community Board'].map(reformat_community_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_borough_column(data):\n",
    "    # The Borough field is mostly empty, so we have to get that from the zip codes                                                                                                                                 \n",
    "    bronx_zips = {\n",
    "        10451, 10452, 10453, 10454, 10455, 10456, 10457, 10458, 10459, 10460, 10461, 10462, 10463, 10464, 10465, 10466,\n",
    "        10467, 10468, 10469, 10470, 10471, 10472, 10473, 10474, 10475}\n",
    "    brooklyn_zips = {\n",
    "        11201, 11203, 11204, 11205, 11206, 11207, 11208, 11209, 11210, 11211, 11212, 11213, 11214, 11215, 11216, 11217,\n",
    "        11218, 11219, 11220, 11221, 11222, 11223, 11224, 11225, 11226, 11228, 11229, 11230, 11231, 11232, 11233, 11234,\n",
    "        11235, 11236, 11236, 11237, 11237, 11238, 11238, 11239, 11239, 11241, 11241, 11242, 11242, 11243, 11243, 11249,\n",
    "        11249, 11252, 11252, 11256}\n",
    "    manhattan_zips = {\n",
    "        10001, 10002, 10003, 10004, 10005, 10006, 10007, 10009, 10010, 10011, 10012, 10013, 10014, 10015, 10016, 10017,\n",
    "        10018, 10019, 10020, 10021, 10022, 10023, 10024, 10025, 10026, 10027, 10028, 10029, 10030, 10031, 10032, 10033,\n",
    "        10034, 10035, 10036, 10037, 10038, 10039, 10040, 10041, 10044, 10045, 10048, 10055, 10060, 10069, 10090, 10095,\n",
    "        10098, 10099, 10103, 10104, 10105, 10106, 10107, 10110, 10111, 10112, 10115, 10118, 10119, 10120, 10121, 10122,\n",
    "        10123, 10128, 10151, 10152, 10153, 10154, 10155, 10158, 10161, 10162, 10165, 10166, 10167, 10168, 10169, 10170,\n",
    "        10171, 10172, 10173, 10174, 10175, 10176, 10177, 10178, 10199, 10270, 10271, 10278, 10279, 10280, 10281, 10282}\n",
    "    queens_zips = {\n",
    "        11004, 11101, 11102, 11103, 11104, 11105, 11106, 11109, 11351, 11354, 11355, 11356, 11357, 11358, 11359, 11360,\n",
    "        11361, 11362, 11363, 11364, 11365, 11366, 11367, 11368, 11369, 11370, 11371, 11372, 11373, 11374, 11375, 11377,\n",
    "        11378, 11379, 11385, 11411, 11412, 11413, 11414, 11415, 11416, 11417, 11418, 11419, 11420, 11421, 11422, 11423,\n",
    "        11426, 11427, 11428, 11429, 11430, 11432, 11433, 11434, 11435, 11436, 11691, 11692, 11693, 11694, 11697}\n",
    "    staten_island_zips = {\n",
    "        10301, 10302, 10303, 10304, 10305, 10306, 10307, 10308, 10309, 10310, 10311, 10312, 10314}\n",
    "    borough_mapping = {}\n",
    "    borough_mapping.update({zip: 'Bronx' for zip in bronx_zips})\n",
    "    borough_mapping.update({zip: 'Brooklyn' for zip in brooklyn_zips})\n",
    "    borough_mapping.update({zip: 'Manhattan' for zip in manhattan_zips})\n",
    "    borough_mapping.update({zip: 'Queens' for zip in queens_zips})\n",
    "    borough_mapping.update({zip: 'Staten Island' for zip in staten_island_zips})\n",
    "    data['Calculated Borough'] = data['Incident Zip'].map(lambda zip: borough_mapping[zip] if zip in borough_mapping else 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://data.cityofnewyork.us/Public-Safety/Police-Precincts/78dh-3ptz\n",
    "precincts_shapefile = '/home/thejakeschmidt/311-open-data-analysis/illegal_parking/data/precinct_shapes/geo_export_1d0f5023-ecf5-4d19-833e-83428f65f9ff.shp'\n",
    "\n",
    "# Copied from https://stackoverflow.com/a/20007730\n",
    "def ordinal(n):\n",
    "    return '%d%s' % (n, 'tsnrhtdd'[(n/10%10!=1)*(n%10<4)*n%10::4])\n",
    "\n",
    "def get_precinct_name(raw_precinct):\n",
    "    if raw_precinct == 14:\n",
    "        return 'Midtown South'\n",
    "    if raw_precinct == 18:\n",
    "        return 'Midtown North'\n",
    "    if raw_precinct == 22:\n",
    "        return 'Central Park'\n",
    "    return ordinal(raw_precinct)\n",
    "\n",
    "def get_precinct_for_point(precincts_rtree, precinct_shapes, precinct_names, lat, lng):\n",
    "    if pd.isnull(lat) or pd.isnull(lng):\n",
    "        return 'unknown'\n",
    "    point = shapely.geometry.Point(lng, lat)\n",
    "    containing_precincts = [p for p in precincts_rtree.intersection((lng, lat))\n",
    "                            if precinct_shapes[p].contains(point)]\n",
    "    if len(containing_precincts) > 1:\n",
    "        raise Exception('Found multiple precincts for point (' + str(lat) + ', ' + str(lng) + '): ' + str(containing_precincts))\n",
    "    if len(containing_precincts) == 0:\n",
    "        return 'unknown'\n",
    "    return precinct_names[containing_precincts[0]]\n",
    "\n",
    "def get_precinct_names_and_numbers():\n",
    "    precinct_names_and_numbers = []\n",
    "    for i, precinct_shape in enumerate(fiona.open(precincts_shapefile)):\n",
    "        precinct_number = int(precinct_shape['properties']['precinct'])\n",
    "        precinct_names_and_numbers.append((get_precinct_name(precinct_number), precinct_number))\n",
    "    return precinct_names_and_numbers\n",
    "\n",
    "precincts_sorting_order = {name: i for name, i in get_precinct_names_and_numbers()}\n",
    "unknown_precinct_sorting_order = max([i for _, i in precincts_sorting_order.iteritems()]) + 1\n",
    "def get_precinct_sorting_order(precinct_name):\n",
    "    if precinct_name in precincts_sorting_order:\n",
    "        return precincts_sorting_order[precinct_name]\n",
    "    return unknown_precinct_sorting_order\n",
    "\n",
    "def add_precinct_column(data):\n",
    "    precinct_names = []\n",
    "    precinct_shapes = []\n",
    "    precincts_rtree = rtree.index.Index()\n",
    "    for i, precinct_shape in enumerate(fiona.open(precincts_shapefile)):\n",
    "        precinct_names.append(get_precinct_name(int(precinct_shape['properties']['precinct'])))\n",
    "        precinct_shapes.append(shapely.geometry.asShape(precinct_shape['geometry']))\n",
    "        precincts_rtree.insert(i, shapely.geometry.asShape(precinct_shape['geometry']).bounds)    \n",
    "\n",
    "    # Optional progress bar support; disable by commenting out this line and changing progress_apply to apply\n",
    "    tqdm_notebook().pandas(desc=\"Adding precincts\")\n",
    "    data['Calculated Precinct'] = data[['Latitude', 'Longitude']].progress_apply(\n",
    "        lambda row: get_precinct_for_point(\n",
    "            precincts_rtree, precinct_shapes, precinct_names, row['Latitude'], row['Longitude']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://data.cityofnewyork.us/City-Government/City-Council-Districts/yusd-j4xi\n",
    "council_districts_shapefile = '/home/thejakeschmidt/311-open-data-analysis/illegal_parking/data/council_district_shapes/geo_export_16ddf551-ecd0-45f5-9681-5b2046184eb1.shp'\n",
    "\n",
    "# Theoretically available at https://data.cityofnewyork.us/City-Government/Council-Members/uvw5-9znb,\n",
    "# but that's out of date as of 2018-01-25. I made my own with the two columns I need.\n",
    "council_members_raw = pd.read_csv('data/Council_Members.csv')\n",
    "council_members = list(council_members_raw.apply(lambda row: (row['NAME'], row['DISTRICT']), axis=1))\n",
    "council_members_by_district = {district: name for name, district in council_members}\n",
    "\n",
    "def get_council_district_name(council_district):\n",
    "    return '{} ({})'.format(council_district, council_members_by_district[council_district])\n",
    "\n",
    "def get_council_district_for_point(council_districts_rtree, council_district_shapes, lat, lng):\n",
    "    if pd.isnull(lat) or pd.isnull(lng):\n",
    "        return 'unknown'\n",
    "    point = shapely.geometry.Point(lng, lat)\n",
    "    containing_council_districts = [\n",
    "        d for d in council_districts_rtree.intersection((lng, lat))\n",
    "        if council_district_shapes[d].contains(point)]\n",
    "    if len(containing_council_districts) > 1:\n",
    "        raise Exception(\n",
    "            'Found multiple council districts for point (' + str(lat) + ', ' + str(lng) + '): ' +\n",
    "            str(containing_council_districts))\n",
    "    if len(containing_council_districts) == 0:\n",
    "        return 'unknown'\n",
    "    return get_council_district_name(containing_council_districts[0])\n",
    "\n",
    "def add_council_district_column(data):\n",
    "    council_district_shapes = {}\n",
    "    council_districts_rtree = rtree.index.Index()\n",
    "    for council_district_shape in fiona.open(council_districts_shapefile):\n",
    "        council_district = int(council_district_shape['properties']['coun_dist'])\n",
    "        council_district_shapes[council_district] = shapely.geometry.asShape(council_district_shape['geometry'])\n",
    "        council_districts_rtree.insert(\n",
    "            council_district, shapely.geometry.asShape(council_district_shape['geometry']).bounds)\n",
    "\n",
    "    # Optional progress bar support; disable by commenting out this line and changing progress_apply to apply\n",
    "    tqdm_notebook().pandas(desc=\"Adding council districts\")\n",
    "    data['Calculated Council District'] = data[['Latitude', 'Longitude']].progress_apply(\n",
    "        lambda row: get_council_district_for_point(\n",
    "            council_districts_rtree, council_district_shapes, row['Latitude'], row['Longitude']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regenerate enhanced data (only needed if definitions change)\n",
    "\n",
    "# data = read_raw_data()\n",
    "# add_community_board_column(data)\n",
    "# add_date_and_time_columns(data)\n",
    "# add_borough_column(data)\n",
    "# add_summons_column(data)\n",
    "# add_action_column(data)\n",
    "# add_precinct_column(data) # Warning: takes about 2-3 hours on my computer\n",
    "# add_council_district_column(data) # Warning: takes about 2-3 hours on my computer\n",
    "# data = data.rename(columns={'Council District': 'Calculated Council District'})\n",
    "# data.to_pickle('data/enhanced_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "data = pd.read_pickle('data/enhanced_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating 2d breakdowns\n",
    "##### These calculate fractions of successful outcomes (action, summons, or both) by two breakdown columns (e.g. community board and descriptor), and output CSV files. They present a lot of data densely, but aren't as easy to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_outcome_fraction(data, breakdown_column1, breakdown_column2, outcome_column, outcome_values):\n",
    "    \"\"\"Groups data by two breakdown columns, with values being the fraction of specified values in an outcome column.\"\"\"\n",
    "    data = data.copy()\n",
    "    data['synthesized_outcome_value'] = data[outcome_column].isin(outcome_values)\n",
    "    outcome_counts = (data.groupby([breakdown_column1, breakdown_column2, 'synthesized_outcome_value'])\n",
    "                       .size().unstack().fillna(0))\n",
    "    return (outcome_counts[True] / (outcome_counts[True] + outcome_counts[False])).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate by-borough CSVs\n",
    "get_2d_outcome_fraction(\n",
    "    data, 'Descriptor', 'Calculated Borough', 'Resolution Description', [SUMMONS_DESCRIPTION])\\\n",
    ".to_csv('out/summons_by_borough_and_descriptor.csv')\n",
    "get_2d_outcome_fraction(\n",
    "    data, 'Descriptor', 'Calculated Borough', 'Resolution Description', [ACTION_DESCRIPTION])\\\n",
    ".to_csv('out/action_by_borough_and_descriptor.csv')\n",
    "get_2d_outcome_fraction(\n",
    "    data, 'Descriptor', 'Calculated Borough', 'Resolution Description', [SUMMONS_DESCRIPTION, ACTION_DESCRIPTION])\\\n",
    ".to_csv('out/positive_outcome_by_borough_and_descriptor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate by-CB CSVs\n",
    "get_2d_outcome_fraction(\n",
    "    data.loc[~data['Calculated Community Board'].str.contains('Unspecified')].copy(),\n",
    "    'Descriptor', 'Calculated Community Board', 'Resolution Description', [SUMMONS_DESCRIPTION])\\\n",
    ".to_csv('out/summons_by_cb_and_descriptor.csv')\n",
    "get_2d_outcome_fraction(\n",
    "    data.loc[~data['Calculated Community Board'].str.contains('Unspecified')].copy(),\n",
    "    'Descriptor', 'Calculated Community Board', 'Resolution Description', [ACTION_DESCRIPTION])\\\n",
    ".to_csv('out/action_by_cb_and_descriptor.csv')\n",
    "get_2d_outcome_fraction(\n",
    "    data.loc[~data['Calculated Community Board'].str.contains('Unspecified')].copy(),\n",
    "    'Descriptor', 'Calculated Community Board', 'Resolution Description', [SUMMONS_DESCRIPTION, ACTION_DESCRIPTION])\\\n",
    ".to_csv('out/positive_outcome_by_cb_and_descriptor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate by-precinct CSVs\n",
    "get_2d_outcome_fraction(\n",
    "    data, 'Descriptor', 'Calculated Precinct', 'Resolution Description', [SUMMONS_DESCRIPTION])\\\n",
    ".to_csv('out/summons_by_precinct_and_descriptor.csv')\n",
    "get_2d_outcome_fraction(\n",
    "    data, 'Descriptor', 'Calculated Precinct', 'Resolution Description', [ACTION_DESCRIPTION])\\\n",
    ".to_csv('out/action_by_precinct_and_descriptor.csv')\n",
    "get_2d_outcome_fraction(\n",
    "    data, 'Descriptor', 'Calculated Precinct', 'Resolution Description', [SUMMONS_DESCRIPTION, ACTION_DESCRIPTION])\\\n",
    ".to_csv('out/positive_outcome_by_precinct_and_descriptor.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating 1d breakdowns\n",
    "##### These calculate the number and fraction of outcomes (action, summons, and other) broken down by one dimension, for only a single descriptor (e.g. \"Blocked Bike Lane\" or \"Blocked Sidewalk\"), and writes them to Google Sheets. These are easier to read and more actionable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_1d_outcome_breakdown(data, descriptor, breakdown_column, breakdown_sorting_key=lambda v: v):\n",
    "    outcome_mapping = {ACTION_DESCRIPTION: '\"Took action\"',\n",
    "                       SUMMONS_DESCRIPTION: '\"Issued summons\"'}\n",
    "\n",
    "    filtered_data = data.loc[(data['Descriptor'] == descriptor)].copy()\n",
    "    filtered_data['outcome'] = filtered_data['Resolution Description'].apply(\n",
    "        lambda desc: outcome_mapping[desc] if desc in outcome_mapping else 'None')\n",
    "\n",
    "    by_outcome = filtered_data\\\n",
    "     .groupby([breakdown_column, 'outcome'])\\\n",
    "     .size()\\\n",
    "     .unstack()\\\n",
    "     .fillna(0)\n",
    "\n",
    "    by_outcome[breakdown_column] = by_outcome.index\n",
    "    by_outcome['sorting_key'] = by_outcome[breakdown_column].apply(breakdown_sorting_key)\n",
    "    by_outcome.sort_values(by=['sorting_key'], inplace=True)\n",
    "    by_outcome.drop('sorting_key', axis=1, inplace=True)\n",
    "\n",
    "    by_outcome['Total reports'] = by_outcome[['\"Took action\"', '\"Issued summons\"', 'None']].sum(axis=1)\n",
    "    return by_outcome[['\"Took action\"', '\"Issued summons\"', 'Total reports']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cb_breakdown(data, descriptor):\n",
    "    def get_sorting_key(cb):\n",
    "        parts = cb.rsplit(' ', 1)\n",
    "        return (parts[0], int(parts[1][2:]))\n",
    "    return generate_1d_outcome_breakdown(\n",
    "        data.loc[~data['Calculated Community Board'].str.contains('Unspecified')],\n",
    "        descriptor, 'Calculated Community Board', get_sorting_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_borough_breakdown(data, descriptor):\n",
    "    return generate_1d_outcome_breakdown(data, descriptor, 'Calculated Borough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_precinct_breakdown(data, descriptor):\n",
    "    return generate_1d_outcome_breakdown(data, descriptor, 'Calculated Precinct', get_precinct_sorting_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_council_district_breakdown(data, descriptor):\n",
    "    def get_sorting_key(council_district):\n",
    "        if council_district == 'unknown':\n",
    "            return 99999\n",
    "        return int(council_district.split(' ')[0])\n",
    "    return generate_1d_outcome_breakdown(data, descriptor, 'Calculated Council District', get_sorting_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These generate CSVs with the 1d breakdown data. Don't bother with these if you can get\n",
    "# write_1d_breakdown_to_sheet working for you, it generates more detailed spreadsheets.\n",
    "\n",
    "# def generate_by_cb_and_by_precinct_csvs(data, descriptor, csv_name_fragment):\n",
    "#     generate_cb_breakdown(data, descriptor).to_csv('out/' + csv_name_fragment + '_by_cb.csv')\n",
    "#     generate_precinct_breakdown(data, descriptor).to_csv('out/' + csv_name_fragment + '_by_precinct.csv')\n",
    "\n",
    "# generate_by_cb_and_by_precinct_csvs(data, 'Blocked Bike Lane', 'blocked_bike_lane')\n",
    "# generate_by_cb_and_by_precinct_csvs(data, 'Blocked Crosswalk', 'blocked_crosswalk')\n",
    "# generate_by_cb_and_by_precinct_csvs(data, 'Blocked Sidewalk', 'blocked_sidewalk')\n",
    "# generate_by_cb_and_by_precinct_csvs(data, 'Parking Permit Improper Use', 'parking_permit_improper_use')\n",
    "# generate_by_cb_and_by_precinct_csvs(data, 'Posted Parking Sign Violation', 'posted_parking_sign_violation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_conditional_formatting_rule(spreadsheet, worksheet_index, column, midpoint_value):\n",
    "    request = {\n",
    "        'addConditionalFormatRule': {\n",
    "            'rule': {\n",
    "                'ranges': [{\n",
    "                    'sheetId': spreadsheet[worksheet_index].id,\n",
    "                    'startRowIndex': 1,\n",
    "                    'endRowIndex': 100,\n",
    "                    'startColumnIndex': column,\n",
    "                    'endColumnIndex': column+1\n",
    "                }],\n",
    "                'gradientRule': {\n",
    "                    'minpoint': {\n",
    "                        # light red berry 2\n",
    "                        'color': {\n",
    "                            'red': 0.866,\n",
    "                            'green': 0.494,\n",
    "                            'blue': 0.420\n",
    "                        },\n",
    "                        'type': 'PERCENTILE',\n",
    "                        'value': '5'\n",
    "                    },\n",
    "                    'midpoint': {\n",
    "                        'color': {\n",
    "                            'red': 1,\n",
    "                            'green': 1,\n",
    "                            'blue': 1\n",
    "                        },\n",
    "                        'type': 'NUMBER',\n",
    "                        'value': str(midpoint_value)\n",
    "                    },\n",
    "                    'maxpoint': {\n",
    "                        # light green 2\n",
    "                        'color': {\n",
    "                            'red': 0.714,\n",
    "                            'green': 0.843,\n",
    "                            'blue': 0.659\n",
    "                        },\n",
    "                        'type': 'PERCENTILE',\n",
    "                        'value': '95'\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "            'index': 0\n",
    "        }\n",
    "    }\n",
    "    # This is hitting an internal-ish pygsheets API, which probably isn't very stable over time.\n",
    "    spreadsheet.client.sheet.batch_update(spreadsheet.id, request, fields='*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_1d_breakdown_to_sheet(\n",
    "        df, spreadsheet, worksheet_index, title, breakdown_column_display_name,\n",
    "        breakdown_column_width):\n",
    "    \"\"\"Takes a dataframe returned from generate_1d_outcome_breakdown and writes it to a Google Sheet.\"\"\"\n",
    "    # 1a. Add extra columns for percentages\n",
    "    df = df.copy()\n",
    "    breakdown_column = df.index.name\n",
    "    df = df.reset_index(drop=False).copy()\n",
    "    \n",
    "    total_actions = df['\"Took action\"'].sum()\n",
    "    total_summons = df['\"Issued summons\"'].sum()\n",
    "    total_reports = df['Total reports'].sum()\n",
    "    \n",
    "    # 1b. Insert a line for the totals\n",
    "    total_line = pd.DataFrame(\n",
    "        {breakdown_column: '',\n",
    "         '\"Took action\"': '=SUM(B3:B{})'.format(len(df) + 2),\n",
    "         '\"Issued summons\"': '=SUM(D3:D{})'.format(len(df) + 2),\n",
    "         'Total reports': '=SUM(F3:F{})'.format(len(df) + 2)},\n",
    "        index=['Total'], columns=df.columns)\n",
    "    df = pd.concat([total_line, df], sort=False).reset_index(drop=True)\n",
    "\n",
    "    # 1c. Add percentage columns and put everything in order\n",
    "    df['\"Took action\" %'] = pd.Series(['=B{}/F{}'.format(i + 2, i + 2) for i in range(len(df))])\n",
    "    df['\"Issued summons\" %'] = pd.Series(['=D{}/F{}'.format(i + 2, i + 2) for i in range(len(df))])\n",
    "    df = df[[breakdown_column, '\"Took action\"', '\"Took action\" %', '\"Issued summons\"', '\"Issued summons\" %', 'Total reports']]\n",
    "    \n",
    "    # 2. Write to spreadsheet\n",
    "    \n",
    "    sheet = spreadsheet[worksheet_index]\n",
    "    \n",
    "    sheet.set_dataframe(df, (1, 1))\n",
    "    sheet.cell('A1').value = breakdown_column_display_name\n",
    "\n",
    "    bold_cell = pygsheets.Cell('A1', '')\n",
    "    bold_cell.set_text_format('bold', True)\n",
    "    sheet.range('A1:F2', returnas='range').apply_format(bold_cell)\n",
    "\n",
    "    percent_cell = pygsheets.Cell('A1', '')\n",
    "    percent_cell.set_number_format(pygsheets.FormatType.PERCENT, '0.0%')\n",
    "    sheet.range('C2:C{}'.format(len(df)+2), returnas='range').apply_format(percent_cell)\n",
    "    sheet.range('E2:E{}'.format(len(df)+2), returnas='range').apply_format(percent_cell)\n",
    "\n",
    "    # The DataRange.apply_format overwrites the bold, so we have to redo that for the\n",
    "    # cells that are bold percentages.\n",
    "    sheet.cell('C2').set_text_format('bold', True)\n",
    "    sheet.cell('E2').set_text_format('bold', True)\n",
    "    \n",
    "    sheet.frozen_rows = 2\n",
    "    sheet.frozen_cols = 1\n",
    "    \n",
    "    sheet.adjust_column_width(0, pixel_size=breakdown_column_width)\n",
    "    sheet.adjust_column_width(1, pixel_size=91)\n",
    "    sheet.adjust_column_width(2, pixel_size=106)\n",
    "    sheet.adjust_column_width(3, pixel_size=126)\n",
    "    sheet.adjust_column_width(4, pixel_size=141)\n",
    "    sheet.adjust_column_width(5, pixel_size=109)\n",
    "\n",
    "    sheet.title = title\n",
    "\n",
    "    add_conditional_formatting_rule(spreadsheet, worksheet_index, 2, float(total_actions) / total_reports)\n",
    "    add_conditional_formatting_rule(spreadsheet, worksheet_index, 4, float(total_summons) / total_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_breakdown_sheets(data, descriptor):\n",
    "    # Note: you have to create a spreadsheet with the right name first.\n",
    "    spreadsheet = creds.open('311 \"{}\" reports'.format(descriptor))\n",
    "\n",
    "    # WARNING: This clears out all existing worksheets!\n",
    "    if not any([worksheet.title == 'Loading...' for worksheet in spreadsheet.worksheets()]):\n",
    "        spreadsheet.add_worksheet('Loading...')\n",
    "    # pygsheets doesn't seem to like when you delete worksheets while iterating over .worksheets(),\n",
    "    # so we have to do it a little more awkwardly.\n",
    "    while True:\n",
    "        non_loading_worksheets = [\n",
    "            worksheet for worksheet in spreadsheet.worksheets() if worksheet.title != 'Loading...']\n",
    "        if len(non_loading_worksheets) > 0:\n",
    "            spreadsheet.del_worksheet(non_loading_worksheets[0])\n",
    "        else:\n",
    "            break\n",
    "    spreadsheet[0].clear()\n",
    "\n",
    "    data_2018 = data.loc[data['Calculated Year'] == 2018]\n",
    "    \n",
    "    about_worksheet = spreadsheet[0]\n",
    "    about_worksheet.cell('A1').value = (\n",
    "        'This spreadsheet breaks down the \"{}\" reports sent to 311 from 2010-2018. The worksheet tabs ' +\n",
    "        'show the available breakdowns: by borough, by community board, by NYPD precinct, ' +\n",
    "        'and by City Council district. Each breakdown is done once with all available data, and once ' +\n",
    "        'with 2018 data only.').format(descriptor)\n",
    "    about_worksheet.cell('A2').value = (\n",
    "        'The code that generates these spreadsheets is available at ' +\n",
    "        'https://github.com/TheJakeSchmidt/311-open-data-analysis, and the author is at ' +\n",
    "        'https://twitter.com/TheJakeSchmidt. Feel free to tweet questions or requests at me, ' +\n",
    "        'and I\\'ll see what I can do!')\n",
    "    about_worksheet.adjust_column_width(0, pixel_size=600)\n",
    "    about_worksheet.adjust_column_width(0, pixel_size=600)\n",
    "    about_worksheet.cell('A1').wrap_strategy = 'WRAP'\n",
    "    about_worksheet.cell('A2').wrap_strategy = 'WRAP'\n",
    "    about_worksheet.title = 'About'\n",
    "\n",
    "    spreadsheet.add_worksheet('Loading...')\n",
    "    write_1d_breakdown_to_sheet(\n",
    "        generate_borough_breakdown(data_2018, descriptor),\n",
    "        spreadsheet, 1, 'By borough (2018)', 'Borough', 83)\n",
    "\n",
    "    spreadsheet.add_worksheet('Loading...')\n",
    "    write_1d_breakdown_to_sheet(\n",
    "        generate_borough_breakdown(data, descriptor),\n",
    "        spreadsheet, 2, 'By borough (2010-2018)', 'Borough', 83)\n",
    "\n",
    "    spreadsheet.add_worksheet('Loading...')\n",
    "    write_1d_breakdown_to_sheet(\n",
    "        generate_cb_breakdown(data_2018, descriptor),\n",
    "        spreadsheet, 3, 'By community board (2018)', 'Community board', 118)\n",
    "\n",
    "    spreadsheet.add_worksheet('Loading...')\n",
    "    write_1d_breakdown_to_sheet(\n",
    "        generate_cb_breakdown(data, descriptor),\n",
    "        spreadsheet, 4, 'By community board (2010-2018)', 'Community board', 118)\n",
    "\n",
    "    spreadsheet.add_worksheet('Loading...')\n",
    "    write_1d_breakdown_to_sheet(\n",
    "        generate_precinct_breakdown(data_2018, descriptor),\n",
    "        spreadsheet, 5, 'By NYPD precinct (2018)', 'Precinct', 93)\n",
    "\n",
    "    spreadsheet.add_worksheet('Loading...')\n",
    "    write_1d_breakdown_to_sheet(\n",
    "        generate_precinct_breakdown(data, descriptor),\n",
    "        spreadsheet, 6, 'By NYPD precinct (2010-2018)', 'Precinct', 93)\n",
    "\n",
    "    spreadsheet.add_worksheet('Loading...')\n",
    "    write_1d_breakdown_to_sheet(\n",
    "        generate_council_district_breakdown(data_2018, descriptor),\n",
    "        spreadsheet, 7, 'By city council district (2018)', 'Council district', 159)\n",
    "\n",
    "    spreadsheet.add_worksheet('Loading...')\n",
    "    write_1d_breakdown_to_sheet(\n",
    "        generate_council_district_breakdown(data, descriptor),\n",
    "        spreadsheet, 8, 'By city council district (2010-2018)', 'Council district', 159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_breakdown_sheets(data, 'Blocked Bike Lane')\n",
    "#write_breakdown_sheets(data, 'Blocked Sidewalk')\n",
    "#write_breakdown_sheets(data, 'Parking Permit Improper Use')\n",
    "#write_breakdown_sheets(data, 'Posted Parking Sign Violation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating time-based breakdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_minutes = data.loc[~data['Calculated Resolution Time'].isnull()].copy()\n",
    "with_minutes['Calculated Resolution Minutes'] = ((\n",
    "    (with_minutes['Calculated Resolution Time'] // np.timedelta64(15, 'm')).astype('int') * 15)\n",
    "    .clip(upper=1440))\n",
    "generate_1d_outcome_breakdown(with_minutes, 'Blocked Bike Lane', 'Calculated Resolution Minutes')\\\n",
    ".reindex(pd.Index(range(0, 1441, 15))).to_csv('out/by_resolution_minutes.csv')\n",
    "# Interesting: no apparent correlation; summons and actions are both pretty consistent for the first 10-12 hours.\n",
    "# Small downward trend in actions over the first 8 hours, but really not much. Hardly explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
